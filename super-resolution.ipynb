{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import h5py\n",
    "\n",
    "import bcolz\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, InputLayer, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit memory used by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_session().close()\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre/post processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1, 1, 3))\n",
    "\n",
    "# Function to subtract imagenet mean and transpose RGB to BGR\n",
    "preproc = lambda x: (x - vgg_mean)[:, :, :, ::-1]\n",
    "\n",
    "# Function to transpose BGR to RGB, add imagenet mean, then clip the result\n",
    "deproc = lambda x,s: np.clip(x.reshape(s)[:, :, :, ::-1] + vgg_mean, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define convolutional part of VGG16 model, with lamdba layer to pre-process input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_input_layer = InputLayer((288, 288, 3))\n",
    "\n",
    "def add_convolutional_layers(model):\n",
    "    blocks = [\n",
    "        (2, 64),\n",
    "        (2, 128),\n",
    "        (3, 256),\n",
    "        (3, 512),\n",
    "        (3, 512)]\n",
    "    for b in range(len(blocks)):\n",
    "        block = blocks[b]\n",
    "        layers = block[0]\n",
    "        filters = block[1]\n",
    "        prefix = 'block' + str(b + 1)\n",
    "        for i in range(layers):\n",
    "            name = prefix + '_conv' + str(i + 1)\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu', padding='same', name=name))\n",
    "        name = prefix + '_pool'\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), name=name))\n",
    "\n",
    "vgg = Sequential()\n",
    "vgg.add(vgg_input_layer)\n",
    "vgg.add(Lambda(preproc, name='lambda'))\n",
    "add_convolutional_layers(vgg)\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable=False\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'https://github.com/fchollet/deep-learning-models'\n",
    "weights_url = repo + '/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "local_name = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = get_file(local_name, weights_url, cache_subdir='models')\n",
    "vgg.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use content loss to create a super-resolution network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define upsampling network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Conv2D(filters, (size, size), strides=stride, padding=mode)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1))\n",
    "    x = conv_block(x, nf, 3, (1,1), act=False)\n",
    "    return layers.add([x, ip])\n",
    "\n",
    "def deconv_block(x, filters, size, shape, stride=(2,2)):\n",
    "    x = Deconv2D(filters, (size, size), strides=stride, padding='same', output_shape=(None,) + shape)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = Conv2D(filters, (size, size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "inp = Input((72, 72, 3))\n",
    "x = conv_block(inp, 64, 9, (1,1))\n",
    "for i in range(4): \n",
    "    x = res_block(x)\n",
    "x = up_block(x, 64, 3)\n",
    "x = up_block(x, 64, 3)\n",
    "x = Conv2D(3, (9, 9), activation='tanh', padding='same')(x)\n",
    "outp = Lambda(lambda x: (x + 1) * 127.5)(x)\n",
    "outp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outp(m, ln):\n",
    "    return m.get_layer('block{}_conv1'.format(ln)).output\n",
    "\n",
    "def mean_sqr_b(diff): \n",
    "    dims = list(range(1,K.ndim(diff)))\n",
    "    return K.expand_dims(K.sqrt(K.mean(diff**2, dims)), 0)\n",
    "\n",
    "w = [0.1, 0.8, 0.1]\n",
    "\n",
    "def content_fn(x): \n",
    "    res = 0; \n",
    "    n = len(w)\n",
    "    for i in range(n): \n",
    "        res += mean_sqr_b(x[i]-x[i+n]) * w[i]\n",
    "    return res\n",
    "\n",
    "vgg_content = Model(vgg_input_layer.input, [get_outp(vgg, o) for o in [1,2,3]])\n",
    "vgg1 = vgg_content(vgg_input)\n",
    "vgg2 = vgg_content(outp)\n",
    "\n",
    "m_sr = Model(inputs=[inp, vgg_input], outputs=Lambda(content_fn)(vgg1 + vgg2))\n",
    "m_sr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 2000\n",
    "arr_lr = bcolz.open('data/super-resolution/trn_resized_72.bc')[:num_images]\n",
    "arr_hr = bcolz.open('data/super-resolution/trn_resized_288.bc')[:num_images]\n",
    "arr_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sr.compile('adam', 'mse')\n",
    "target = np.zeros((num_images, 1))\n",
    "epochs = 8\n",
    "print(m_sr.input_layers[0].is_placeholder)\n",
    "print(m_sr.input_layers[1].is_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sr.fit([arr_lr, arr_hr], target, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sr.fit([arr_lr, arr_hr], target, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract part of the model that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = Model(inp, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = top_model.predict(arr_lr[500:501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr_lr[500].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p[0].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
