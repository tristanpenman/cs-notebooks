{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Users/Tristan/Dropbox/Notebooks/NNDL/data/ex1data1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt, zeros, ones, array, linspace, logspace\n",
    "from pylab import scatter, show, title, xlabel, ylabel, plot, contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the linear regression\n",
    "def compute_cost(X, y, theta):\n",
    "    '''\n",
    "    Comput cost for linear regression\n",
    "    '''\n",
    "    #Number of training samples\n",
    "    m = y.size\n",
    " \n",
    "    predictions = X.dot(theta).flatten()\n",
    " \n",
    "    sqErrors = (predictions - y) ** 2\n",
    " \n",
    "    J = (1.0 / (2 * m)) * sqErrors.sum()\n",
    " \n",
    "    return J\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Performs gradient descent to learn theta\n",
    "    by taking num_items gradient steps with learning\n",
    "    rate alpha\n",
    "    '''\n",
    "    m = y.size\n",
    "    J_history = zeros(shape=(num_iters, 1))\n",
    " \n",
    "    for i in range(num_iters):\n",
    " \n",
    "        predictions = X.dot(theta).flatten()\n",
    " \n",
    "        errors_x1 = (predictions - y) * X[:, 0]\n",
    "        errors_x2 = (predictions - y) * X[:, 1]\n",
    " \n",
    "        theta[0][0] = theta[0][0] - alpha * (1.0 / m) * errors_x1.sum()\n",
    "        theta[1][0] = theta[1][0] - alpha * (1.0 / m) * errors_x2.sum()\n",
    " \n",
    "        J_history[i, 0] = compute_cost(X, y, theta)\n",
    " \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data = loadtxt(data_file, delimiter=',')\n",
    "X = data[:, 0]\n",
    "y = data[:, 1]\n",
    "m = y.size\n",
    "it = ones(shape=(m, 2))\n",
    "it[:, 1] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent parameters\n",
    "initial_theta = zeros(shape=(2, 1))\n",
    "iterations = 1500\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find theta\n",
    "theta, history = gradient_descent(it, y, initial_theta, alpha, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use theta to predict profit based on population\n",
    "result = it.dot(theta).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and predictions\n",
    "%matplotlib inline\n",
    "scatter(data[:, 0], data[:, 1], marker='o', c='b')\n",
    "plot(data[:, 0], result)\n",
    "title('Profits distribution')\n",
    "xlabel('Population of City in 10,000s')\n",
    "ylabel('Profit in $10,000s')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the compute_cost function to plot a contour graph showing the value of the cost function $J(\\theta)$ for different values of $\\theta_0$ and $\\theta_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid over which we will calculate J\n",
    "theta0_vals = linspace(-10, 10, 100)\n",
    "theta1_vals = linspace(-1, 4, 100)\n",
    "\n",
    "#initialize J_vals to a matrix of 0's\n",
    "J_vals = zeros(shape=(theta0_vals.size, theta1_vals.size))\n",
    "\n",
    "#Fill out J_vals\n",
    "for t1, element in enumerate(theta0_vals):\n",
    "    for t2, element2 in enumerate(theta1_vals):\n",
    "        thetaT = zeros(shape=(2, 1))\n",
    "        thetaT[0][0] = element\n",
    "        thetaT[1][0] = element2\n",
    "        J_vals[t1, t2] = compute_cost(it, y, thetaT)\n",
    "        \n",
    "#Contour plot\n",
    "J_vals = J_vals.T\n",
    "\n",
    "#Plot J_vals as 15 contours spaced logarithmically between 0.01 and 100\n",
    "contour(theta0_vals, theta1_vals, J_vals, logspace(-2, 3, 20))\n",
    "xlabel('theta_0')\n",
    "ylabel('theta_1')\n",
    "scatter(theta[0][0], theta[1][0])\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that none of this is necessary because the value for $\\theta$ can be calculated directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
