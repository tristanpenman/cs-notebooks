{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import h5py\n",
    "\n",
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "    \n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "# In case we are going to use the TensorFlow backend we need to explicitly set the Theano image ordering\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3, 1, 1))\n",
    "\n",
    "# Subtract pre-calculated mean of imagenet dataset and transpose RGB to BGR\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "def add_convolutional_layers(model):\n",
    "    blocks = [\n",
    "        (2, 64),\n",
    "        (2, 128),\n",
    "        (3, 256),\n",
    "        (3, 512),\n",
    "        (3, 512)]\n",
    "    for block in blocks:\n",
    "        layers = block[0]\n",
    "        filters = block[1]\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1,1)))\n",
    "            model.add(Convolution2D(filters, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "def add_fully_connected_layers(model):\n",
    "    for i in range(2):\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "def build_model():\n",
    "    image_shape = (3, 224, 224)\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Pre-processing layer\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=image_shape, output_shape=image_shape))\n",
    "    \n",
    "    # Create convolutional layers\n",
    "    add_convolutional_layers(model)\n",
    "    model.add(Flatten())\n",
    "        \n",
    "    # Create fully-connected layers\n",
    "    add_fully_connected_layers(model)\n",
    "        \n",
    "    # Output layer\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def finetune_model(model, num_categories):\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.add(Dense(num_categories, activation='softmax'))\n",
    "    \n",
    "def get_batches(path, \n",
    "                batch_size,\n",
    "                gen=image.ImageDataGenerator(), \n",
    "                target_size=(224, 224), \n",
    "                shuffle=True, \n",
    "                class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path,\n",
    "                                   batch_size=batch_size,\n",
    "                                   target_size=target_size, \n",
    "                                   shuffle=shuffle, \n",
    "                                   class_mode=class_mode)\n",
    "    \n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/dogscats-redux/full/\"\n",
    "batch_size = 64\n",
    "trn_batches = get_batches(path + 'train', batch_size)\n",
    "val_batches = get_batches(path + 'valid', batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local_path = 'vgg16.h5'\n",
    "model_url = 'http://files.fast.ai/models/vgg16.h5'\n",
    "model = build_model()\n",
    "model.load_weights(get_file(model_local_path, model_url, cache_subdir='models'))\n",
    "finetune_model(model, trn_batches.num_classes)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_steps = int(np.ceil(trn_batches.samples / batch_size))\n",
    "val_steps = int(np.ceil(val_batches.samples / batch_size))\n",
    "\n",
    "print(\"Training steps:\", trn_steps)\n",
    "print(\"Validation steps:\", val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "results_dir = os.path.join(path, \"results\")\n",
    "%mkdir -p {results_dir}\n",
    "for epoch in range(num_epochs):\n",
    "    model.fit_generator(trn_batches, trn_steps, 1, validation_data=val_batches, validation_steps=val_steps)\n",
    "    model.save_weights(os.path.join(results_dir, (\"model.%d\" % epoch) + \".h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(trn_batches)\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_batch_size = 4\n",
    "tst_batches = get_batches(path + 'test', tst_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(tst_batches, int(np.ceil(tst_batches.samples / tst_batch_size)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_indices = random.sample(range(len(pred)), 4)\n",
    "tst_filenames = [os.path.join(path, 'test', tst_batches.filenames[i]) for i in tst_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_images = [image.load_img(filename) for filename in tst_filenames]\n",
    "pred[tst_indices]\n",
    "is_dog = pred[:,1]\n",
    "plots(tst_images, titles=is_dog[tst_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = int(time.time())\n",
    "submission_path = os.path.join(path, 'results', 'submission.{0}.csv'.format(timestamp))\n",
    "is_dog_clipped = is_dog.clip(min=0.05, max=0.95)\n",
    "ids = np.array([int(f[11:f.find('.')]) for f in tst_batches.filenames])\n",
    "submission = np.stack([ids, is_dog_clipped], axis=1)\n",
    "np.savetxt(submission_path, submission, fmt='%d,%.5f', header='id,label', comments='')\n",
    "FileLink(submission_path)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
