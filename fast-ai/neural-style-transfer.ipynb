{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import h5py\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import metrics\n",
    "from imageio import imwrite\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.misc import imsave\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit memory used by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define convolutional part of VGG16 model, using average pooling instead of max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_convolutional_layers(model):\n",
    "    blocks = [\n",
    "        (2, 64),\n",
    "        (2, 128),\n",
    "        (3, 256),\n",
    "        (3, 512),\n",
    "        (3, 512)]\n",
    "    for b in range(len(blocks)):\n",
    "        block = blocks[b]\n",
    "        layers = block[0]\n",
    "        filters = block[1]\n",
    "        prefix = 'block' + str(b + 1)\n",
    "        for i in range(layers):\n",
    "            name = prefix + '_conv' + str(i + 1)\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu', padding='same', name=name))\n",
    "        name = prefix + '_pool'\n",
    "        model.add(AveragePooling2D((2, 2), strides=(2, 2), name=name))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 3), name='input'))\n",
    "add_convolutional_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'https://github.com/fchollet/deep-learning-models'\n",
    "weights_url = repo + '/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "local_name = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = get_file(local_name, weights_url, cache_subdir='models')\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreating an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/neural-style/n01558993_9684.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1, 1, 3))\n",
    "\n",
    "# Function to subtract imagenet mean and transpose RGB to BGR\n",
    "preproc = lambda x: (x - vgg_mean)[:, :, :, ::-1]\n",
    "\n",
    "# Function to transpose BGR to RGB, add imagenet mean, then clip the result\n",
    "deproc = lambda x,s: np.clip(x.reshape(s)[:, :, :, ::-1] + vgg_mean, 0, 255)\n",
    "\n",
    "# Preprocess image\n",
    "img_arr = preproc(np.expand_dims(np.array(img), 0))\n",
    "shp = img_arr.shape\n",
    "shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_img = lambda shape: np.random.uniform(0, 1, shape)\n",
    "x = rand_img(shp)\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use solver to minimise loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('block5_conv1').output\n",
    "layer_model = Model(model.input, layer)\n",
    "targ = K.variable(layer_model.predict(img_arr))\n",
    "\n",
    "class Evaluator(object):\n",
    "    def __init__(self, f, shp):\n",
    "        self.f = f\n",
    "        self.shp = shp\n",
    "        \n",
    "    def loss(self, x):\n",
    "        loss_, self.grad_values = self.f([x.reshape(self.shp)])\n",
    "        return loss_.astype(np.float64)\n",
    "\n",
    "    def grads(self, x):\n",
    "        return self.grad_values.flatten().astype(np.float64)\n",
    "\n",
    "def solve_image(eval_obj, niter, x):\n",
    "    for i in range(niter):\n",
    "        x, min_val, info = fmin_l_bfgs_b(eval_obj.loss, x.flatten(), fprime=eval_obj.grads, maxfun=20)\n",
    "        x = np.clip(x, -127, 127)\n",
    "        print('Loss value at iteration {}: {}'.format(i + 1, min_val))\n",
    "        if i == niter - 1:\n",
    "            filename = 'iteration_' + str(i) + '.png'\n",
    "            imwrite(filename, deproc(x.copy(), shp)[0].astype('uint8'))\n",
    "            plt.imshow(Image.open(filename))\n",
    "    return x\n",
    "\n",
    "iterations=10\n",
    "loss = K.mean(metrics.mse(layer, targ))\n",
    "grads = K.gradients(loss, model.input)\n",
    "fn = K.function([model.input], [loss]+grads)\n",
    "evaluator = Evaluator(fn, shp)\n",
    "x = solve_image(evaluator, iterations, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = Image.open('data/neural-style/starry_night.png')\n",
    "style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_arr = preproc(style[:,:,:,:3])\n",
    "shp = style_arr.shape\n",
    "shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=shp[1:], name='input'))\n",
    "add_convolutional_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {l.name: l.output for l in model.layers}\n",
    "layers = [outputs['block{}_conv1'.format(o)] for o in range(1,3)]\n",
    "layers_model = Model(model.input, layers)\n",
    "targs = [K.variable(o) for o in layers_model.predict(style_arr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    # We want each row to be a channel, and the columns to be flattened x,y locations\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    # The dot product of this with its transpose shows the correlation \n",
    "    # between each pair of channels\n",
    "    return K.dot(features, K.transpose(features)) / x.get_shape().num_elements()\n",
    "\n",
    "def style_loss(x, targ):\n",
    "    return K.mean(metrics.mse(gram_matrix(x), gram_matrix(targ)))\n",
    "\n",
    "loss = sum(style_loss(l1[0], l2[0]) for l1,l2 in zip(layers, targs))\n",
    "grads = K.gradients(loss, model.input)\n",
    "style_fn = K.function([model.input], [loss]+grads)\n",
    "evaluator = Evaluator(style_fn, shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand_img(shp)\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scipy.ndimage.filters.gaussian_filter(x, [0,2,2,0])\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = solve_image(evaluator, iterations, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arr(arr):\n",
    "    plt.imshow(deproc(arr, arr.shape)[0].astype('uint8'))\n",
    "\n",
    "w,h = style.size\n",
    "src = img_arr[:,:h,:w]\n",
    "plot_arr(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = [outputs['block{}_conv2'.format(o)] for o in range(1,6)]\n",
    "content_name = 'block4_conv2'\n",
    "content_layer = outputs[content_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_model = Model(model.input, style_layers)\n",
    "style_targs = [K.variable(o) for o in style_model.predict(style_arr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model = Model(model.input, content_layer)\n",
    "content_targ = K.variable(content_model.predict(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_wgts = [0.05,0.2,0.2,0.25,0.3]\n",
    "loss = sum(style_loss(l1[0], l2[0])*w\n",
    "           for l1,l2,w in zip(style_layers, style_targs, style_wgts))\n",
    "loss += K.mean(metrics.mse(content_layer, content_targ) / 10)\n",
    "grads = K.gradients(loss, model.input)\n",
    "transfer_fn = K.function([model.input], [loss]+grads)\n",
    "evaluator = Evaluator(transfer_fn, shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50\n",
    "x = rand_img(shp)\n",
    "x = solve_image(evaluator, iterations, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand_img(shp)\n",
    "x = scipy.ndimage.filters.gaussian_filter(x, [0,2,2,0])\n",
    "x = solve_image(evaluator, iterations, x)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
